{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVgk3+kN5QExMIH9aHZ0Oj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harinijuluru/Explainable-AI/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question -1"
      ],
      "metadata": {
        "id": "j40Jpco4OhCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "\n",
        "# 1. Dataset\n",
        "\n",
        "data = {\n",
        "    \"GoogleAds_(₹1000s)\": [1, 2, 3, 1, 2],\n",
        "    \"BooksSold\": [100, 130, 160, 110, 140]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# 2. Baseline value\n",
        "\n",
        "baseline = df[\"BooksSold\"].mean()\n",
        "\n",
        "# 3. Linear Regression\n",
        "\n",
        "X = df[[\"GoogleAds_(₹1000s)\"]]\n",
        "y = df[\"BooksSold\"]\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coef = model.coef_[0]\n",
        "\n",
        "\n",
        "# 4. Predictions & SHAP values\n",
        "\n",
        "df[\"Predicted_BooksSold\"] = model.predict(X).round(4)\n",
        "df[\"Baseline\"] = round(baseline, 4)\n",
        "df[\"SHAP\"] = (df[\"Predicted_BooksSold\"] - baseline).round(4)\n",
        "df[\"Baseline_plus_SHAP\"] = (df[\"Baseline\"] + df[\"SHAP\"]).round(4)\n",
        "\n",
        "# 5. Residuals & Over/Under\n",
        "\n",
        "df[\"Residual_(Actual-Predicted)\"] = (df[\"BooksSold\"] - df[\"Predicted_BooksSold\"]).round(4)\n",
        "df[\"Over_Under\"] = df[\"Residual_(Actual-Predicted)\"].apply(\n",
        "    lambda r: \"Underprediction (model too low)\" if r > 0\n",
        "    else (\"Overprediction (model too high)\" if r < 0 else \"Exact\")\n",
        ")\n",
        "\n",
        "\n",
        "# 6. Model performance\n",
        "\n",
        "r2 = r2_score(y, df[\"Predicted_BooksSold\"])\n",
        "mse = mean_squared_error(y, df[\"Predicted_BooksSold\"])\n",
        "mae = mean_absolute_error(y, df[\"Predicted_BooksSold\"])\n",
        "\n",
        "# 7. Output results\n",
        "\n",
        "print(\"=== Linear Regression Model ===\")\n",
        "print(f\"Predicted_BooksSold = {intercept:.4f} + {coef:.4f} × GoogleAds_(₹1000s)\")\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "print(f\"Coefficient: {coef:.4f} (books per ₹1000 Google Ads)\")\n",
        "print(\"\\n=== Baseline ===\")\n",
        "print(f\"Baseline (mean BooksSold): {baseline:.4f}\")\n",
        "\n",
        "print(\"\\n=== Model Performance ===\")\n",
        "print(f\"R-squared: {r2:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "\n",
        "print(\"\\n=== Detailed Table ===\")\n",
        "print(df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmSnZV07OSux",
        "outputId": "5448e681-b165-4c02-c479-aee2b765d787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Linear Regression Model ===\n",
            "Predicted_BooksSold = 77.8571 + 27.8571 × GoogleAds_(₹1000s)\n",
            "Intercept: 77.8571\n",
            "Coefficient: 27.8571 (books per ₹1000 Google Ads)\n",
            "\n",
            "=== Baseline ===\n",
            "Baseline (mean BooksSold): 128.0000\n",
            "\n",
            "=== Model Performance ===\n",
            "R-squared: 0.9530\n",
            "MSE: 21.4286\n",
            "MAE: 4.2857\n",
            "\n",
            "=== Detailed Table ===\n",
            " GoogleAds_(₹1000s)  BooksSold  Predicted_BooksSold  Baseline     SHAP  Baseline_plus_SHAP  Residual_(Actual-Predicted)                      Over_Under\n",
            "                  1        100             105.7143     128.0 -22.2857            105.7143                      -5.7143 Overprediction (model too high)\n",
            "                  2        130             133.5714     128.0   5.5714            133.5714                      -3.5714 Overprediction (model too high)\n",
            "                  3        160             161.4286     128.0  33.4286            161.4286                      -1.4286 Overprediction (model too high)\n",
            "                  1        110             105.7143     128.0 -22.2857            105.7143                       4.2857 Underprediction (model too low)\n",
            "                  2        140             133.5714     128.0   5.5714            133.5714                       6.4286 Underprediction (model too low)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question-2"
      ],
      "metadata": {
        "id": "gHq7yeXwUENC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "# 1. Dataset\n",
        "\n",
        "data = {\n",
        "    \"Footfall\": [100, 80, 120, 90, 60],\n",
        "    \"Promotions\": [1, 0, 1, 0, 1],\n",
        "    \"Sales\": [1500, 1000, 1700, 1100, 900]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# 2. Inputs & Target\n",
        "\n",
        "X = df[[\"Footfall\", \"Promotions\"]].astype(float)\n",
        "y = df[\"Sales\"].astype(float)\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Fit Multiple Linear Regression\n",
        "# ------------------------------\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(X, y)\n",
        "coefs = model.coef_\n",
        "intercept = model.intercept_\n",
        "\n",
        "# 4. Baseline (mean of all Sales)\n",
        "\n",
        "baseline = y.mean()\n",
        "\n",
        "\n",
        "# 5. SHAP-like Contributions\n",
        "\n",
        "means_x = X.mean()\n",
        "shap_vals = (X - means_x) * coefs\n",
        "\n",
        "\n",
        "# 6. Predictions\n",
        "\n",
        "preds = model.predict(X)\n",
        "sum_shap = shap_vals.sum(axis=1)\n",
        "preds_from_baseline_shap = baseline + sum_shap\n",
        "\n",
        "\n",
        "# 7. Create Results Table\n",
        "\n",
        "results = df.copy()\n",
        "results[\"Predicted_Sales\"] = preds.round(2)\n",
        "results[\"Baseline\"] = baseline\n",
        "results[\"SHAP_Footfall\"] = shap_vals[\"Footfall\"].round(2)\n",
        "results[\"SHAP_Promotions\"] = shap_vals[\"Promotions\"].round(2)\n",
        "results[\"Sum_SHAP\"] = sum_shap.round(2)\n",
        "results[\"Baseline+Sum_SHAP\"] = preds_from_baseline_shap.round(2)\n",
        "results[\"Residual\"] = (results[\"Predicted_Sales\"] - results[\"Sales\"]).round(2)\n",
        "results[\"Over_Under\"] = results.apply(\n",
        "    lambda r: \"Overprediction\" if r[\"Predicted_Sales\"] > r[\"Sales\"]\n",
        "              else (\"Underprediction\" if r[\"Predicted_Sales\"] < r[\"Sales\"] else \"Exact\"),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "\n",
        "# 8. Display Results\n",
        "\n",
        "print(\"\\n=== MODEL SUMMARY ===\")\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "print(f\"Coef_Footfall: {coefs[0]:.4f}\")\n",
        "print(f\"Coef_Promotions: {coefs[1]:.4f}\")\n",
        "print(f\"Baseline (mean Sales): {baseline:.2f}\")\n",
        "print(\"\\nVerification that predictions match baseline + SHAP sum:\",\n",
        "      np.allclose(preds, preds_from_baseline_shap))\n",
        "\n",
        "print(\"\\n=== RESULTS TABLE ===\")\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THmFYaS4UD0A",
        "outputId": "cf40cd83-2f70-416c-b910-9c2b8dbef93b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MODEL SUMMARY ===\n",
            "Intercept: -95.6522\n",
            "Coef_Footfall: 13.4783\n",
            "Coef_Promotions: 204.3478\n",
            "Baseline (mean Sales): 1240.00\n",
            "\n",
            "Verification that predictions match baseline + SHAP sum: True\n",
            "\n",
            "=== RESULTS TABLE ===\n",
            "   Footfall  Promotions  Sales  Predicted_Sales  Baseline  SHAP_Footfall  \\\n",
            "0       100           1   1500          1456.52    1240.0         134.78   \n",
            "1        80           0   1000           982.61    1240.0        -134.78   \n",
            "2       120           1   1700          1726.09    1240.0         404.35   \n",
            "3        90           0   1100          1117.39    1240.0           0.00   \n",
            "4        60           1    900           917.39    1240.0        -404.35   \n",
            "\n",
            "   SHAP_Promotions  Sum_SHAP  Baseline+Sum_SHAP  Residual       Over_Under  \n",
            "0            81.74    216.52            1456.52    -43.48  Underprediction  \n",
            "1          -122.61   -257.39             982.61    -17.39  Underprediction  \n",
            "2            81.74    486.09            1726.09     26.09   Overprediction  \n",
            "3          -122.61   -122.61            1117.39     17.39   Overprediction  \n",
            "4            81.74   -322.61             917.39     17.39   Overprediction  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question-3\n"
      ],
      "metadata": {
        "id": "LmbUB1XIUcCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# 1. Load Diabetes Dataset\n",
        "\n",
        "data = load_diabetes()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name=\"disease_progression\")\n",
        "\n",
        "# Split into train & test sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. Fit Multiple Linear Regression\n",
        "\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model parameters\n",
        "coefs = pd.Series(model.coef_, index=X.columns)\n",
        "intercept = model.intercept_\n",
        "\n",
        "# 3. Baseline (mean of target in training data)\n",
        "\n",
        "baseline = y_train.mean()\n",
        "\n",
        "\n",
        "# 4. Compute SHAP-like contributions (linear model method)\n",
        "\n",
        "means_train = X_train.mean()\n",
        "shap_vals_test = (X_test - means_train) * coefs\n",
        "\n",
        "# Predictions from model\n",
        "preds_test = model.predict(X_test)\n",
        "\n",
        "# Sum of SHAP contributions per test row\n",
        "sum_shap_test = shap_vals_test.sum(axis=1)\n",
        "\n",
        "# Predictions from baseline + SHAP sum\n",
        "preds_from_baseline_shap = baseline + sum_shap_test\n",
        "\n",
        "\n",
        "# 5. Verify decomposition\n",
        "\n",
        "assert np.allclose(preds_test, preds_from_baseline_shap), \"SHAP decomposition failed!\"\n",
        "\n",
        "\n",
        "# 6. Create Results Table\n",
        "\n",
        "results = X_test.copy()\n",
        "results[\"Actual\"] = y_test.values\n",
        "results[\"Predicted\"] = preds_test.round(2)\n",
        "results[\"Baseline\"] = baseline\n",
        "for col in shap_vals_test.columns:\n",
        "    results[f\"SHAP_{col}\"] = shap_vals_test[col].round(2)\n",
        "results[\"Sum_SHAP\"] = sum_shap_test.round(2)\n",
        "results[\"Baseline+Sum_SHAP\"] = preds_from_baseline_shap.round(2)\n",
        "results[\"Residual\"] = (results[\"Predicted\"] - results[\"Actual\"]).round(2)\n",
        "results[\"Over_Under\"] = results[\"Residual\"].apply(lambda r: \"Overprediction\" if r > 0 else (\"Underprediction\" if r < 0 else \"Exact\"))\n",
        "\n",
        "\n",
        "# 7. Output Model Summary & Results\n",
        "\n",
        "print(\"\\n=== MODEL SUMMARY ===\")\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "print(\"Coefficients:\")\n",
        "print(coefs)\n",
        "print(f\"\\nBaseline (mean of training target): {baseline:.2f}\")\n",
        "print(\"Verification that predictions match baseline + SHAP sum:\",\n",
        "      np.allclose(preds_test, preds_from_baseline_shap))\n",
        "\n",
        "print(\"\\n=== SAMPLE RESULTS (first 5 patients) ===\")\n",
        "print(results.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOPmI87DUeS6",
        "outputId": "b485637f-a7d1-4e95-923e-531adc75daab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MODEL SUMMARY ===\n",
            "Intercept: 151.3456\n",
            "Coefficients:\n",
            "age     37.904021\n",
            "sex   -241.964362\n",
            "bmi    542.428759\n",
            "bp     347.703844\n",
            "s1    -931.488846\n",
            "s2     518.062277\n",
            "s3     163.419983\n",
            "s4     275.317902\n",
            "s5     736.198859\n",
            "s6      48.670657\n",
            "dtype: float64\n",
            "\n",
            "Baseline (mean of training target): 153.74\n",
            "Verification that predictions match baseline + SHAP sum: True\n",
            "\n",
            "=== SAMPLE RESULTS (first 5 patients) ===\n",
            "          age       sex       bmi        bp        s1        s2        s3  \\\n",
            "287  0.045341 -0.044642 -0.006206 -0.015999  0.125019  0.125198  0.019187   \n",
            "211  0.092564 -0.044642  0.036907  0.021872 -0.024960 -0.016658  0.000779   \n",
            "72   0.063504  0.050680 -0.004050 -0.012556  0.103003  0.048790  0.056003   \n",
            "321  0.096197 -0.044642  0.051996  0.079265  0.054845  0.036577 -0.076536   \n",
            "73   0.012648  0.050680 -0.020218 -0.002228  0.038334  0.053174 -0.006584   \n",
            "\n",
            "           s4        s5        s6  ...  SHAP_s1  SHAP_s2  SHAP_s3  SHAP_s4  \\\n",
            "287  0.034309  0.032432 -0.005220  ...  -116.97    65.28     3.30     9.34   \n",
            "211 -0.039493 -0.022517 -0.021788  ...    22.73    -8.21     0.29   -10.98   \n",
            "72  -0.002592  0.084492 -0.017646  ...   -96.46    25.69     9.31    -0.82   \n",
            "321  0.141322  0.098648  0.061054  ...   -51.61    19.37   -12.35    38.80   \n",
            "73   0.034309 -0.005142 -0.009362  ...   -36.22    27.96    -0.91     9.34   \n",
            "\n",
            "     SHAP_s5  SHAP_s6  Sum_SHAP  Baseline+Sum_SHAP  Residual       Over_Under  \n",
            "287    22.98    -0.35    -14.19             139.55    -79.45  Underprediction  \n",
            "211   -17.47    -1.15     25.78             179.52    109.52   Overprediction  \n",
            "72     61.31    -0.95    -19.70             134.04    -67.96  Underprediction  \n",
            "321    71.73     2.88    137.68             291.42     61.42   Overprediction  \n",
            "73     -4.68    -0.55    -29.95             123.79     12.79   Overprediction  \n",
            "\n",
            "[5 rows x 27 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4\n"
      ],
      "metadata": {
        "id": "SzQc9LEWnI3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install pandas scikit-learn shap\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import shap\n",
        "\n",
        "# 1. Example dataset (replace with your actual data)\n",
        "data = {\n",
        "    'study_time': [2, 3, 1, 4, 2, 3],\n",
        "    'parent_edu': ['high', 'low', 'medium', 'high', 'low', 'medium'],\n",
        "    'absences': [4, 10, 2, 0, 6, 1],\n",
        "    'G3': [15, 10, 12, 18, 11, 14]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 2. Features & target\n",
        "X = df.drop(columns=['G3'])\n",
        "y = df['G3']\n",
        "\n",
        "# 3. Preprocess & split\n",
        "cat_cols = X.select_dtypes(include=['object']).columns\n",
        "pre = ColumnTransformer(\n",
        "    [('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_cols)],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
        "\n",
        "# 4. Train model\n",
        "model = LinearRegression()\n",
        "X_train_enc = pre.fit_transform(X_train)\n",
        "X_test_enc = pre.transform(X_test)\n",
        "model.fit(X_train_enc, y_train)\n",
        "\n",
        "# 5. Baseline & SHAP\n",
        "baseline = y_train.mean()\n",
        "explainer = shap.LinearExplainer(model, X_train_enc)\n",
        "shap_values = explainer.shap_values(X_test_enc)\n",
        "\n",
        "# 6. Check formula\n",
        "preds = model.predict(X_test_enc)\n",
        "print(\"Baseline:\", baseline)\n",
        "print(\"Predictions:\", preds)\n",
        "print(\"Baseline + sum(SHAP):\", baseline + shap_values.sum(axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OKOC20BYnIhi",
        "outputId": "35c9aaf6-7638-4744-dcdd-9ce2a73f1d00"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline: 14.666666666666666\n",
            "Predictions: [17.72222222 18.38888889  5.16666667]\n",
            "Baseline + sum(SHAP): [17.72222222 18.38888889  5.16666667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}